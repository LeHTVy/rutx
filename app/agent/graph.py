"""
LangGraph Agent - State Machine for Pentest Agent
==================================================

Proper agentic flow:
1. Intent Node (LLM) - Classify user input
2. Planner Node (LLM) - Suggest tools, NO auto-execution
3. Confirm Node - Wait for user approval
4. Executor Node (CODE) - Run tools via registry
5. Analyzer Node (LLM) - Decide DONE/CONTINUE

Key principle: LLM plans, CODE executes, LLM analyzes.
"""
from typing import TypedDict, List, Dict, Any, Literal, Optional, Annotated
from enum import Enum
import operator
import json
import re

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from app.llm import get_llm_config
from app.tools.registry import get_registry


# ============================================================
# STATE SCHEMA
# ============================================================

class Message(TypedDict):
    """A message in the conversation."""
    role: str  # "user" or "assistant"
    content: str


class AgentState(TypedDict):
    """State passed between nodes in the graph."""
    
    # User input
    query: str
    
    # Conversation history (persisted across turns)
    messages: List[Message]
    
    # Intent classification
    intent: str  # "security_task", "question", "confirm", "tool_select"
    
    # Planning
    suggested_tools: List[str]
    suggestion_message: str
    tool_params: Dict[str, Any]
    
    # Execution
    confirmed: bool
    selected_tools: List[str]
    execution_results: Dict[str, Any]
    
    # Memory/Context (accumulated)
    context: Annotated[Dict[str, Any], operator.or_]
    
    # Output
    response: str
    
    # Flow control
    next_action: str  # "plan", "confirm", "execute", "analyze", "respond", "end"


# ============================================================
# LLM CLIENT (LangChain-Ollama)
# ============================================================

# Global model setting for switching
_current_model = None

def get_current_model() -> str:
    """Get current model, defaulting to config."""
    global _current_model
    if _current_model:
        return _current_model
    config = get_llm_config()
    return config.get_model()

def set_current_model(model: str):
    """Set the global model for all LLM calls."""
    global _current_model
    _current_model = model
    print(f"  ğŸ”„ Model switched to: {model}")


class OllamaClient:
    """LangChain-Ollama client for LLM calls."""
    
    def __init__(self, model: str = None):
        self.model = model or get_current_model()
        self._llm = None
    
    def _get_llm(self):
        """Lazy initialization of ChatOllama."""
        if self._llm is None:
            from langchain_ollama import ChatOllama
            self._llm = ChatOllama(
                model=self.model,
                temperature=0.3,
                num_ctx=4096,
            )
        return self._llm
    
    def generate(self, prompt: str, system: str = None, timeout: int = 120) -> str:
        """Generate response using LangChain-Ollama."""
        try:
            import sys
            import threading
            import time
            
            # Spinner animation
            spinner_chars = "â ‹â ™â ¹â ¸â ¼â ´â ¦â §â ‡â "
            spinner_running = True
            
            def spin():
                i = 0
                while spinner_running:
                    sys.stdout.write(f"\r  {spinner_chars[i % len(spinner_chars)]} Thinking ({self.model})...")
                    sys.stdout.flush()
                    time.sleep(0.1)
                    i += 1
            
            # Start spinner in background
            spinner_thread = threading.Thread(target=spin, daemon=True)
            spinner_thread.start()
            
            llm = self._get_llm()
            
            # Build messages
            from langchain_core.messages import HumanMessage, SystemMessage
            messages = []
            if system:
                messages.append(SystemMessage(content=system))
            messages.append(HumanMessage(content=prompt))
            
            # Invoke
            response = llm.invoke(messages)
            result = response.content if response else ""
            
            # Stop spinner
            spinner_running = False
            spinner_thread.join(timeout=0.5)
            
            if result:
                # Strip thinking tags from deepseek-r1
                import re
                result = re.sub(r'<think>.*?</think>', '', result, flags=re.DOTALL).strip()
                print(f"  âœ… LLM responded ({len(result)} chars)")
            return result
            
        except Exception as e:
            print(f"  âŒ LLM error: {e}")
            return ""


# ============================================================
# NODE IMPLEMENTATIONS
# ============================================================

def intent_node(state: AgentState) -> AgentState:
    """
    Classify user intent using LLM.
    
    Returns:
    - security_task: Needs tool execution (scan, exploit, enumerate, etc.)
    - memory_query: User wants to see stored data (subdomains, results, findings)
    - question: Simple question, answer directly
    - confirm: User confirming/denying previous suggestion
    """
    # Sanitize input - remove box-drawing characters and extra whitespace
    query = state["query"]
    # Remove common terminal box-drawing and special characters
    query = re.sub(r'[â”‚â”Œâ”â””â”˜â”œâ”¤â”¬â”´â”¼â”€â•â•‘â•”â•—â•šâ•â• â•£â•¦â•©â•¬]', '', query)
    query = re.sub(r'\s+', ' ', query)  # Collapse whitespace
    query = query.lower().strip()
    
    suggested_tools = state.get("suggested_tools", [])
    context = state.get("context", {})
    
    # Quick confirmations (exact matches - no LLM needed)
    if query in ["yes", "y", "ok", "go", "run", "execute", "proceed"]:
        return {**state, "intent": "confirm", "confirmed": True}

    if suggested_tools and ("yes" in query or query.endswith(" y")):
        print(f"  ğŸ“‹ Confirming pending suggestion: {suggested_tools}")
        return {**state, "intent": "confirm", "confirmed": True}
    
    if query in ["no", "n", "cancel", "stop", "abort"]:
        return {**state, "intent": "confirm", "confirmed": False}
    
    if query.startswith(("yes", "ok", "let's", "lets", "go with")):
        is_short_confirmation = len(query) < 20
        
        selected = []
        for tool in suggested_tools:
            if tool.lower() in query:
                selected.append(tool)
        
        if selected:
            return {
                **state,
                "intent": "confirm",
                "confirmed": True,
                "selected_tools": selected
            }
        
        # Only confirm if we have pending tools AND query is short
        if suggested_tools and is_short_confirmation:
            return {**state, "intent": "confirm", "confirmed": True}
    
    # ============================================================
    # LLM-BASED INTENT CLASSIFICATION
    # ============================================================
    llm = OllamaClient()
    
    # Build context summary
    context_summary = ""
    if context.get("tools_run"):
        context_summary += f"Tools already run: {', '.join(context.get('tools_run', []))}\n"
    if context.get("subdomain_count"):
        context_summary += f"Subdomains found: {context.get('subdomain_count')}\n"
    if context.get("has_ports"):
        context_summary += "Port scan completed\n"
    if context.get("detected_tech"):
        context_summary += f"Technologies detected: {', '.join(context.get('detected_tech', [])[:5])}\n"
    if context.get("subdomains"):
        context_summary += f"Subdomains stored in memory: {len(context.get('subdomains', []))}\n"
    
    # Check if query contains a domain/IP - strong signal for SECURITY_TASK
    domain_pattern = r'(?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}'
    has_domain = bool(re.search(domain_pattern, state["query"]))
    
    prompt = f'''Classify this user message for a penetration testing assistant.

USER MESSAGE: "{state["query"]}"

CONTEXT:
{context_summary if context_summary else "No prior context"}
{"NOTE: Message contains a domain/IP address" if has_domain else ""}

CLASSIFY AS ONE OF:
- SECURITY_TASK: User wants to RUN NEW SCANS or use security tools
  Examples: "scan the domain", "find vulnerabilities", "use nuclei", "run nmap"
  If the message mentions a domain/IP AND wants a NEW scan â†’ SECURITY_TASK

- MEMORY_QUERY: User wants to SEE/RETRIEVE STORED DATA from previous scans
  Examples: "show me the subdomains", "list the results", "what did we find",
  "show the scan data", "display stored subdomains", "show me what's in database",
  "list findings", "what vulnerabilities were found", "show me the data",
  "show me emails", "list emails", "show hosts", "list IPs", "show ports",
  "show open ports", "list the emails", "what emails did we find",
  "show me the scan results", "list discovered paths", "show credentials"
  If user asks to SHOW/LIST/DISPLAY existing data â†’ MEMORY_QUERY

- QUESTION: User is asking a conceptual question or needs explanation (no action)
  Examples: "what is XSS", "explain this CVE", "who are you", "how does SQL injection work"

Respond with ONLY one word: SECURITY_TASK or MEMORY_QUERY or QUESTION'''

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # KEYWORD-BASED MEMORY QUERY DETECTION (before LLM call)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    query_lower = state["query"].lower()
    
    # Check for memory query keywords
    memory_keywords = [
        "show me email", "list email", "show email",
        "show me subdomain", "list subdomain", "show subdomain",
        "show me host", "list host", "show host",
        "show me ip", "list ip", "show ip",
        "show me port", "list port", "show port", "show open port",
        "show me vuln", "list vuln", "show vuln",
        "show me path", "list path", "discovered path",
        "show me cred", "list cred", "cracked",
        "show me data", "show the data", "list data",
        "show me result", "show result", "list result",
        "show me finding", "list finding",
        "what did we find", "what was found",
        "show me asn", "list asn",
        "show me url", "list url", "interesting url",
        "show me exploit", "list exploit",
        "show me smb", "list smb", "smb share", "smb user",
        "show me wordpress", "wp user", "wp plugin",
        "show me technolog", "list technolog",
        "show me waf",
    ]
    
    for keyword in memory_keywords:
        if keyword in query_lower:
            print(f"  â†’ Intent: MEMORY_QUERY (keyword: '{keyword}')")
            return {**state, "intent": "memory_query"}
    
    print("  ğŸ§  LLM classifying intent...")
    
    try:
        response = llm.generate(prompt, timeout=30)
        response_clean = response.strip().upper().replace("_", "_")
        
        # Extract intent from response
        if "MEMORY" in response_clean or "QUERY" in response_clean:
            print("  â†’ Intent: MEMORY_QUERY")
            return {**state, "intent": "memory_query"}
        elif "SECURITY" in response_clean or "TASK" in response_clean:
            print("  â†’ Intent: SECURITY_TASK")
            return {**state, "intent": "security_task"}
        elif "QUESTION" in response_clean:
            print("  â†’ Intent: QUESTION")
            return {**state, "intent": "question"}
        else:
            # Default to security_task if ambiguous (action-oriented)
            print(f"  â†’ Intent: SECURITY_TASK (default, LLM said: {response[:50]})")
            return {**state, "intent": "security_task"}
    except Exception as e:
        print(f"  âš ï¸ Intent LLM failed: {e}, defaulting to security_task")
        return {**state, "intent": "security_task"}


def infer_phase(context: dict, llm) -> dict:
    """
    LLM infers the current pentest phase based on context.
    
    Returns: {"phase": 1-4, "reason": "..."}
    
    Phase 1: Reconnaissance - No data yet, gathering info
    Phase 2: Scanning - Have targets, finding vulnerabilities
    Phase 3: Exploitation - Have vulns, attempting access
    Phase 4: Reporting - Have findings, documenting results
    """
    # Build context summary for LLM
    has_subdomains = context.get("has_subdomains", False)
    subdomain_count = context.get("subdomain_count", 0)
    has_ports = context.get("has_ports", False)
    open_ports = context.get("open_ports", [])
    vulns_found = context.get("vulns_found", [])
    services = context.get("services", [])
    tools_run = context.get("tools_run", [])
    exploits_run = context.get("exploits_run", [])
    
    # Quick heuristic first (no LLM call needed for obvious cases)
    if exploits_run or "sqlmap" in tools_run or "hydra" in tools_run or "msfconsole" in tools_run:
        return {"phase": 3, "reason": "Exploitation tools have been run"}
    
    if vulns_found or "nuclei" in tools_run or "nikto" in tools_run:
        return {"phase": 2, "reason": "Vulnerability scanning in progress"}
    
    if has_ports or open_ports or "nmap" in tools_run or "masscan" in tools_run:
        return {"phase": 2, "reason": "Port scanning completed, in scanning phase"}
    
    if has_subdomains or subdomain_count > 0:
        return {"phase": 2, "reason": "Subdomains found, ready for scanning"}
    
    if not tools_run:
        return {"phase": 1, "reason": "No tools run yet, starting reconnaissance"}
    
    # For ambiguous cases, ask LLM
    prompt = f'''You are a penetration testing expert. Analyze this context and determine the current pentest phase.

CURRENT CONTEXT:
- Subdomains found: {subdomain_count}
- Ports scanned: {has_ports}
- Open ports: {open_ports[:5] if open_ports else "none"}
- Vulnerabilities found: {len(vulns_found)} 
- Services detected: {services[:5] if services else "none"}
- Tools already run: {tools_run[-5:] if tools_run else "none"}
- Exploitation attempted: {bool(exploits_run)}

PENTEST PHASES:
1 = Reconnaissance (gathering info, OSINT, subdomains)
2 = Scanning & Enumeration (ports, services, vulnerabilities)
3 = Exploitation (exploiting vulns, gaining access)
4 = Reporting (documenting findings)

Return ONLY a JSON: {{"phase": 1, "reason": "brief explanation"}}'''

    try:
        response = llm.generate(prompt, timeout=30)
        # Clean response
        clean = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()
        
        # Parse JSON
        import json
        match = re.search(r'\{[^}]+\}', clean)
        if match:
            result = json.loads(match.group())
            return {
                "phase": int(result.get("phase", 1)),
                "reason": result.get("reason", "LLM inference")
            }
    except Exception:
        pass
    
    # Default to phase 1 if inference fails
    return {"phase": 1, "reason": "Default - starting reconnaissance"}


def planner_node(state: AgentState) -> AgentState:
    """
    LLM suggests tools using SEMANTIC SEARCH + CONSTRAINED OUTPUT.
    
    Architecture:
    1. Infer current pentest phase from context
    2. Semantic search finds candidate tools from ToolIndex
    3. LLM chooses from candidates ONLY (constrained by phase)
    4. No keyword detection - pure semantic + LLM reasoning
    """
    from app.rag.tool_index import ToolIndex
    from app.rag.tool_metadata import PHASE_NAMES, get_tool_phase
    
    llm = OllamaClient()
    context = state.get("context", {})
    
    # Extract domain/IP from user query if not in context
    domain_pattern = r'(?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}'
    ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
    url_pattern = r'https?://[^\s]+'
    
    # First check for full URL
    url_match = re.search(url_pattern, state["query"])
    if url_match:
        context["url_target"] = url_match.group()
        print(f"  ğŸ”— Extracted URL: {url_match.group()}")
    
    # Check for IP address
    ip_match = re.search(ip_pattern, state["query"])
    if ip_match:
        ip = ip_match.group()
        context["target_ip"] = ip
        context["last_domain"] = ip  # Use IP as domain for tools
        print(f"  ğŸ¯ Extracted IP address: {ip}")
        domain = ip
    else:
        domain_match = re.search(domain_pattern, state["query"])
        if domain_match:
            domain = domain_match.group()
            # Filter provider domains from context, but keep for targeting
            provider_domains = ['windows.net', 'azure.', 'microsoft.', 'amazonaws.', 'cloudfront.', 'google.', 'facebook.']
            if not any(x in domain.lower() for x in provider_domains):
                context["last_domain"] = domain
                print(f"  ğŸ¯ Extracted domain from query: {domain}")
            else:
                # It's a provider URL - still use it as target but don't save to context
                if not context.get("last_domain"):
                    context["target_domain"] = domain  # Temporary target
                domain = context.get("last_domain", domain)  # Fallback to provider domain if no context
                print(f"  â„¹ï¸ Provider URL detected, using: {domain}")
        else:
            domain = context.get("last_domain", "")
    
    # === STEP 0: DETECT USER-MENTIONED TOOLS ===
    from app.tools.registry import get_registry
    registry = get_registry()
    all_tools = registry.list_tools()
    user_mentioned_tools = []
    query_lower = state["query"].lower()
    for tool in all_tools:
        if tool.lower() in query_lower:
            user_mentioned_tools.append(tool)
    
    if user_mentioned_tools:
        print(f"  ğŸ¯ User mentioned tools: {user_mentioned_tools}")
    
    # === STEP 0.5: INFER CURRENT PENTEST PHASE ===
    phase_info = infer_phase(context, llm)
    current_phase = phase_info.get("phase", 1)
    phase_reason = phase_info.get("reason", "")
    context["current_phase"] = current_phase
    print(f"  ğŸ“Š Phase {current_phase} ({PHASE_NAMES.get(current_phase, 'Unknown')}): {phase_reason}")
    
    # === STEP 1: SEMANTIC SEARCH FOR CANDIDATE TOOLS ===
    try:
        tool_index = ToolIndex()
        candidates = tool_index.search(state["query"], n_results=5)
        print(f"  ğŸ” Semantic search found: {[c['name'] for c in candidates]}")
    except Exception as e:
        print(f"  âš ï¸ Tool index error: {e}, using fallback")
        candidates = []
    
    # FORCE user-mentioned tools into candidates if not already there
    candidate_names = [c["name"] for c in candidates]
    for tool in user_mentioned_tools:
        if tool not in candidate_names:
            # Add user-mentioned tool to candidates
            spec = registry.tools.get(tool)
            if spec:
                candidates.insert(0, {"name": tool, "description": spec.description})
                print(f"  â• Added user-requested tool: {tool}")
    
    # If no candidates found, ask user to clarify
    if not candidates:
        return {
            **state,
            "response": "â“ I couldn't find matching tools for your request.\n\nPlease be more specific (e.g., 'scan for vulnerabilities' or 'find subdomains').",
            "next_action": "end"
        }
    
    # Build candidate list for LLM
    candidate_names = [c["name"] for c in candidates]
    candidate_str = "\n".join([f"- {c['name']}: {c['description']}" for c in candidates])
    
    # === SHORTCUT: If user explicitly named tools, use them directly (skip LLM) ===
    if user_mentioned_tools:
        print(f"  âœ… Using user-requested tools directly: {user_mentioned_tools}")
        return {
            **state,
            "suggested_tools": user_mentioned_tools,
            "suggestion_message": f"Running {', '.join(user_mentioned_tools)} as requested.",
            "tool_params": {"domain": domain} if domain else {},
            "context": context,
            "next_action": "confirm"
        }
    
    # === STEP 2: CONSTRAINED LLM SELECTION (only if user didn't specify tools) ===
    context_str = ""
    if context.get("has_subdomains"):
        count = context.get("subdomain_count", 0)
        context_str += f"â€¢ Found {count} subdomains\n"
    if context.get("has_ports"):
        context_str += "â€¢ Port scan completed\n"
    if context.get("subdomains"):
        subs = context.get("subdomains", [])[:5]
        context_str += f"â€¢ Subdomains: {', '.join(subs)}...\n"
    
    tools_run = context.get("tools_run", [])
    if tools_run:
        context_str += f"â€¢ Already ran: {', '.join(tools_run)}\n"
    
    # === CVE-AWARE CONTEXT ENHANCEMENT ===
    cve_context = ""
    detected_tech = context.get("detected_tech", [])
    if detected_tech:
        try:
            from app.rag.unified_memory import get_unified_rag
            rag = get_unified_rag()
            relevant_cves = rag.search_cves_for_tech(detected_tech[:3])
            
            if relevant_cves:
                cve_context = "\nâ€¢ Relevant CVEs for detected technologies:\n"
                for cve in relevant_cves[:3]:
                    cve_id = cve.get("cve_id", "Unknown")
                    desc = cve.get("description", "")[:80]
                    cve_context += f"  - {cve_id}: {desc}...\n"
                print(f"  ğŸ” Found {len(relevant_cves)} relevant CVEs for {detected_tech[:3]}")
        except Exception as e:
            pass  # CVE enhancement is optional
    
    # === CONVERSATION CONTEXT ENHANCEMENT ===
    conv_context = ""
    try:
        from app.rag.unified_memory import get_unified_rag
        rag = get_unified_rag()
        past_context = rag.get_relevant_context(state["query"], domain)
        
        if past_context.get("tool_executions"):
            conv_context = "\nâ€¢ Recent relevant tool executions:\n"
            for exec_info in past_context["tool_executions"][:2]:
                conv_context += f"  - {exec_info.get('tool', 'unknown')}: {exec_info.get('content', '')[:60]}...\n"
    except Exception:
        pass  # Conversation context is optional
    
    prompt = f'''Choose the best tool(s) for this security task.

USER REQUEST: {state["query"]}

CURRENT PENTEST PHASE: {current_phase} - {PHASE_NAMES.get(current_phase, "Unknown")}
(1=Recon, 2=Scanning, 3=Exploitation, 4=Reporting)

CANDIDATE TOOLS (choose ONLY from these):
{candidate_str}

CONTEXT:
{context_str if context_str else "No prior data"}{cve_context}{conv_context}

RULES:
- Choose ONLY from the candidate tools listed above
- Prioritize tools appropriate for the current phase
- Phase 1 (Recon): subdomain discovery, OSINT, DNS enumeration
- Phase 2 (Scanning): port scanning, vulnerability scanning, service detection
- Phase 3 (Exploitation): exploiting vulns, brute-force, gaining access
- **CRITICAL: If user explicitly names tools, include ALL requested tools**
- If user doesn't specify tools, pick the single best one for the current phase
- If CVEs are mentioned, prefer tools that can detect them (like nuclei)
- Return JSON: {{"tools": ["tool1", "tool2"], "message": "I suggest..."}}
- "tools" should be an ARRAY, even if only one tool

Return ONLY valid JSON, no extra text.'''

    response = llm.generate(prompt, timeout=60)
    
    # Remove thinking tags (deepseek-r1)
    clean_response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()
    
    # === STEP 3: PARSE AND VALIDATE ===
    tools = []
    message = ""
    params = {"domain": domain} if domain else {}
    
    # Try JSON extraction
    try:
        json_match = re.search(r'\{[^{}]*\}', clean_response, re.DOTALL)
        if json_match:
            data = json.loads(json_match.group())
            
            # Handle both "tools" (array) and "tool" (string) for compatibility
            raw_tools = data.get("tools") or data.get("tool", [])
            if isinstance(raw_tools, str):
                raw_tools = [raw_tools]
            
            message = data.get("message", "")
            
            # Validate all tools are in candidates
            valid_tools = [t for t in raw_tools if t in candidate_names]
            if valid_tools:
                tools = valid_tools
                print(f"  âœ… LLM selected: {tools} (validated)")
            else:
                print(f"  âš ï¸ LLM selected '{raw_tools}' but not in candidates, using top candidate")
                tools = [candidate_names[0]]
                message = f"I suggest using {candidate_names[0]} for this task."
    except json.JSONDecodeError:
        print(f"  âš ï¸ JSON parse error")
    
    # NO FALLBACK - If LLM didn't return valid tools, fail clearly
    if tools:
        return {
            **state,
            "suggested_tools": tools,
            "suggestion_message": message or f"I suggest using {tools[0]} for this task.",
            "tool_params": params,
            "context": context,
            "next_action": "confirm"
        }
    
    # LLM failed to respond properly - clear error, no hardcoded fallback
    return {
        **state,
        "response": "âš ï¸ LLM failed to select a tool. Please try again or specify a tool directly (e.g., 'run nmap on example.com').",
        "next_action": "end"
    }



def confirm_node(state: AgentState) -> AgentState:
    """
    Handle user confirmation.
    
    This node is reached when user responds to a suggestion.
    User can say "yes lets use amass" to select specific tools.
    """
    if state.get("confirmed", False):
        selected = state.get("selected_tools") or state.get("tools") or state.get("suggested_tools", [])
        
        print(f"  âœ“ User confirmed. Running: {selected}")
        
        return {
            **state,
            "selected_tools": selected,
            "next_action": "executor"
        }
    else:
        # User declined
        return {
            **state,
            "response": "Cancelled. What would you like to do instead?",
            "next_action": "respond"
        }


def executor_node(state: AgentState) -> AgentState:
    """
    Execute tools via registry.
    
    This is PURE CODE - no LLM involvement.
    Auditable, safe, controlled.
    """
    registry = get_registry()
    results = {}
    context = state.get("context", {})
    
    tools = state.get("selected_tools", [])
    params = state.get("tool_params", {})
    
    # CRITICAL: Ensure domain is in params from context
    if not params.get("domain") and context.get("last_domain"):
        params["domain"] = context.get("last_domain")
    if not params.get("domain") and context.get("target_domain"):
        params["domain"] = context.get("target_domain")
        
    if not params.get("target") and context.get("last_domain"):
        params["target"] = context.get("last_domain")
    if not params.get("target") and context.get("target_domain"):
        params["target"] = context.get("target_domain")
    
    # Use full URL if available (for web-based attacks)
    if not params.get("url") and context.get("url_target"):
        params["url"] = context.get("url_target")
        # Also extract domain from URL for target
        url = context.get("url_target")
        if url and not params.get("target"):
            import urllib.parse
            parsed = urllib.parse.urlparse(url)
            params["target"] = parsed.netloc
            params["domain"] = parsed.netloc
    
    # Also build URL for web tools if needed
    domain = params.get("domain") or params.get("target")
    if domain and not params.get("url"):
        params["url"] = f"https://{domain}"
    
    # Also set host for tools that need it
    if domain and not params.get("host"):
        params["host"] = domain
    
    # ============================================================
    # DEFAULT PARAMETERS FOR COMMON TOOLS
    # ============================================================
    
    # Default wordlist paths (common Kali/SecLists locations)
    if not params.get("wordlist"):
        # Try common wordlist locations
        import os
        wordlist_paths = [
            "wordlists/common.txt", 
            "/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt",
            "/usr/share/wordlists/dirb/common.txt",
            "/usr/share/seclists/Discovery/Web-Content/common.txt",
            "/usr/share/wordlists/seclists/Discovery/Web-Content/common.txt",
            "/usr/share/dirb/wordlists/common.txt",
        ]
        for wl in wordlist_paths:
            if os.path.exists(wl):
                params["wordlist"] = wl
                break
        if not params.get("wordlist"):
            # Fallback - use local wordlist
            params["wordlist"] = "wordlists/common.txt"
    
    # For brute-force tools, use password wordlist instead of directory wordlist
    if any(t in ["hydra", "medusa", "john", "hashcat"] for t in tools):
        import os
        password_lists = [
            "wordlists/passwords.txt",
            "/usr/share/wordlists/rockyou.txt",
            "/usr/share/seclists/Passwords/Common-Credentials/10-million-password-list-top-1000.txt",
        ]
        for pwl in password_lists:
            if os.path.exists(pwl):
                params["wordlist"] = pwl
                break
    
    # Default user for brute-force tools (hydra, medusa)
    if not params.get("user"):
        params["user"] = "admin"  # Most common default username
    
    # Default port for nikto if not specified
    if not params.get("port"):
        params["port"] = "443"
    
    # Default ports for port scanners (masscan, nmap)
    # Based on 18 critical hacker ports + common web ports
    if not params.get("ports"):
        # Organized by category:
        # "Dinosaur" (legacy clear-text): 21 FTP, 23 Telnet, 80 HTTP
        # "Steel Door" (secure): 22 SSH, 443 HTTPS
        # "Mail": 25 SMTP, 110 POP3, 143 IMAP, 993 IMAPS, 995 POP3S
        # "Infrastructure": 53 DNS, 67-68 DHCP, 123 NTP
        # "Treasure" (control+data): 139 NetBIOS, 445 SMB, 3389 RDP
        # "Database": 1433 MSSQL, 1521 Oracle, 3306 MySQL, 5432 PostgreSQL
        # "Web Alt": 8080, 8443, 8888
        params["ports"] = "21,22,23,25,53,67,68,80,110,123,135,139,143,443,445,993,995,1433,1521,3306,3389,5432,5900,8080,8443,8888"
    
    # Default query for searchsploit (use domain/tech if available)
    if not params.get("query"):
        detected_tech = context.get("detected_tech", [])
        if detected_tech:
            params["query"] = detected_tech[0]  # Use first detected tech
        else:
            params["query"] = params.get("domain") or params.get("target") or "apache"
    
    # Clean, simplified output - only show what matters
    target_display = params.get("url") or params.get("target") or params.get("domain") or "unknown"
    
    # TODO: Parallel execution - requires refactoring executor into _execute_tool helper
    # For now, run tools sequentially
    if len(tools) > 1:
        print(f"  ğŸš€ Executing {len(tools)} tools SEQUENTIALLY: {', '.join(tools)} on {target_display}")
    else:
        print(f"  ğŸš€ Executing: {', '.join(tools)} on {target_display}")
    
    for tool_name in tools:
        if not registry.is_available(tool_name):
            results[tool_name] = {
                "success": False,
                "output": f"Tool not available: {tool_name}"
            }
            continue
        
        spec = registry.tools.get(tool_name)
        if not spec or not spec.commands:
            results[tool_name] = {
                "success": False,
                "output": f"No commands for: {tool_name}"
            }
            continue
        
        # ============================================================
        # CLATSCOPE OSINT - Python-based, not CLI
        # ============================================================
        if tool_name == "clatscope":
            from app.tools.specs.osint import execute_clatscope, format_clatscope_result
            
            # Determine which OSINT command to run based on params/query
            osint_command = params.get("command", "whois")  # Default to whois
            
            # Auto-detect command from params
            if params.get("ip") or params.get("target"):
                if params.get("ip"):
                    osint_command = "ip"
            if params.get("phone"):
                osint_command = "phone"
            if params.get("email"):
                osint_command = "breach" if "breach" in str(params) else "email"
            
            print(f"  ğŸ” OSINT: {osint_command}")
            
            osint_result = execute_clatscope(osint_command, params)
            formatted = format_clatscope_result(osint_command, osint_result)
            
            results[tool_name] = {
                "success": osint_result.get("success", False),
                "output": formatted,
                "data": osint_result.get("data")
            }
            
            # Update context with OSINT findings
            if osint_result.get("success"):
                data = osint_result.get("data", {})
                if osint_command == "subdomain" and data.get("subdomains"):
                    context["subdomains"] = data["subdomains"]
                    context["subdomain_count"] = len(data["subdomains"])
                    context["has_subdomains"] = True
            
            continue
        
        tool_params = params.copy()
        domain = params.get("domain", params.get("target", ""))
        subdomains = context.get("subdomains", [])
        command = None  
        
        BATCH_SIZE = 50 
        
        if tool_name in ["nmap", "masscan", "nuclei"] and subdomains:
            total_targets = len(subdomains)
            all_outputs = []
            
            num_batches = (total_targets + BATCH_SIZE - 1) // BATCH_SIZE
            
            if num_batches > 1:
                print(f"  ğŸ“‹ Scanning {total_targets} targets in {num_batches} batches")
            
            for batch_num in range(num_batches):
                start_idx = batch_num * BATCH_SIZE
                end_idx = min(start_idx + BATCH_SIZE, total_targets)
                batch_targets = subdomains[start_idx:end_idx]
                
                # Write batch to temp file
                target_file = f"/tmp/snode_targets_{domain.replace('.', '_')}_batch{batch_num+1}.txt"
                with open(target_file, 'w') as f:
                    f.write('\n'.join(batch_targets))
                
                # Only show batch progress for multiple batches
                if num_batches > 1:
                    print(f"  ğŸ“¦ Batch {batch_num+1}/{num_batches}: {len(batch_targets)} targets")
                
                # Configure tool for batch
                batch_params = tool_params.copy()
                if tool_name == "nmap":
                    command = "from_file"
                    batch_params["file"] = target_file
                    batch_params["ports"] = "22,80,443,8080,8443"
                elif tool_name == "nuclei":
                    # Use scan_list for batch targets
                    batch_params["file"] = target_file
                    command = "scan_list"
                elif tool_name == "masscan":
                    batch_params["target"] = target_file
                    command = "scan"
                
                # Execute batch
                batch_result = registry.execute(tool_name, command, batch_params)
                
                if batch_result.success:
                    all_outputs.append(f"=== Batch {batch_num+1} ({len(batch_targets)} targets) ===\n{batch_result.output}")
                else:
                    all_outputs.append(f"=== Batch {batch_num+1} FAILED ===\n{batch_result.error}")
            
            # Combine all batch results
            combined_output = "\n\n".join(all_outputs)
            results[tool_name] = {
                "success": True,
                "output": combined_output,
                "batches": num_batches,
                "total_targets": total_targets
            }
            
            # Update context with scan info
            context["has_ports"] = True
            context["last_scan"] = {"tool": tool_name, "targets": total_targets}
            continue  # Skip the normal execution below
            
        else:
            # Single target mode
            if tool_name in ["nuclei", "nmap", "masscan"]:
                tool_params["target"] = domain
            if tool_name in ["wpscan", "nikto", "httpx", "katana"]:
                tool_params["url"] = f"https://{domain}" if domain and not domain.startswith("http") else domain
            if tool_name in ["subfinder", "amass", "bbot", "dig"]:
                tool_params["domain"] = domain
            
            # Exploit tools need special handling
            if tool_name == "msfconsole":
                # Build search command based on detected tech or ports
                detected_tech = context.get("detected_tech", [])
                if detected_tech:
                    search_term = detected_tech[0] if detected_tech else "apache"
                else:
                    search_term = "apache"  # Default search
                tool_params["command"] = f"search {search_term}; exit"
                print(f"  ğŸ”´ MSF command: search {search_term}")
            
            if tool_name == "searchsploit":
                # Use domain or detected tech as search query
                query = tool_params.get("query", "")
                if not query:
                    detected_tech = context.get("detected_tech", [])
                    if detected_tech:
                        tool_params["query"] = detected_tech[0]
                    else:
                        tool_params["query"] = domain or "apache"
            
            # NMAP: Smart command selection based on user-specified flags
            if tool_name == "nmap":
                user_query = state.get("query", "").lower()
                
                # Detect scan type from user query
                if "-ss" in user_query or "syn scan" in user_query or "stealth" in user_query:
                    command = "syn_scan"
                    print(f"  ğŸ” Nmap: SYN scan (-sS) selected")
                elif "-su" in user_query or "udp" in user_query:
                    command = "udp_scan"
                    print(f"  ğŸ” Nmap: UDP scan (-sU) selected")
                elif "-st" in user_query or "tcp connect" in user_query:
                    command = "tcp_scan"
                    print(f"  ğŸ” Nmap: TCP connect scan (-sT) selected")
                elif "-sv" in user_query or "version" in user_query:
                    command = "version_scan"
                    print(f"  ğŸ” Nmap: Version scan (-sV) selected")
                elif "-o" in user_query or "os detect" in user_query:
                    command = "os_detect"
                    print(f"  ğŸ” Nmap: OS detection (-O) selected")
                elif "-a" in user_query or "aggressive" in user_query:
                    command = "aggressive"
                    print(f"  ğŸ” Nmap: Aggressive scan (-A) selected")
                elif "vuln" in user_query or "vulnerab" in user_query:
                    command = "vuln_scan"
                    print(f"  ğŸ” Nmap: Vulnerability scripts selected")
                elif "full" in user_query or "all ports" in user_query or "-p-" in user_query:
                    command = "full_scan"
                    print(f"  ğŸ” Nmap: Full scan selected")
                elif "ping" in user_query or "-sn" in user_query:
                    command = "ping_sweep"
                    print(f"  ğŸ” Nmap: Ping sweep selected")
                elif "service" in user_query or "-sc" in user_query:
                    command = "service_scan"
                    print(f"  ğŸ” Nmap: Service scan (-sC) selected")
                # command will remain None for default (quick_scan)
            
            # GOBUSTER: Smart command selection
            if tool_name == "gobuster":
                user_query = state.get("query", "").lower()
                if "dns" in user_query or "subdomain" in user_query:
                    command = "dns"
                    print(f"  ğŸ” Gobuster: DNS mode selected")
                elif "redirect" in user_query or "302" in user_query or "wildcard" in user_query:
                    command = "dir_redirects"
                    print(f"  ğŸ” Gobuster: Directory scan (ignore redirects) selected")
            
            # HYDRA: Smart command selection based on target URL/port
            if tool_name == "hydra":
                url = tool_params.get("url", "")
                target = tool_params.get("target", "")
                
                # Detect protocol from URL
                if url.startswith("https://") or url.startswith("http://"):
                    # HTTP-based target
                    if ":2087" in url or "cpanel" in url.lower() or "whm" in url.lower():
                        command = "cpanel"
                        print(f"  ğŸ” Hydra: cPanel detected, using HTTPS form brute-force")
                    elif ":2083" in url:
                        command = "cpanel"  # cPanel user login
                        print(f"  ğŸ” Hydra: cPanel user login detected")
                    else:
                        # Check if we have form details for POST
                        if tool_params.get("form") or tool_params.get("fail_msg"):
                            command = "http_post"
                            print(f"  ğŸ” Hydra: HTTP target, using HTTP form brute-force")
                        else:
                            # Fallback to GET/Basic Auth
                            command = "http_get"
                            if not tool_params.get("path"):
                                tool_params["path"] = "/"
                            print(f"  ğŸ” Hydra: HTTP target (no form details), using HTTP GET/Basic Auth")
                elif ":22" in target or "ssh" in state.get("query", "").lower():
                    command = "ssh"
                elif ":21" in target or "ftp" in state.get("query", "").lower():
                    command = "ftp"
                elif ":3389" in target or "rdp" in state.get("query", "").lower():
                    command = "rdp"
                elif ":445" in target or "smb" in state.get("query", "").lower():
                    command = "smb"
                else:
                    # Default to http_post for web targets
                    command = "http_post"
                    print(f"  ğŸ” Hydra: Defaulting to HTTP brute-force")
        
            # MEDUSA: Smart command selection based on target/ports
            if tool_name == "medusa":
                url = tool_params.get("url", "")
                target = tool_params.get("target", "")
                query = state.get("query", "").lower()
                open_ports = context.get("open_ports", [])
                
                # Check for specific services in open ports or query
                if ":22" in target or "ssh" in query or 22 in open_ports:
                    command = "ssh"
                    print(f"  ğŸ” Medusa: SSH detected")
                elif ":21" in target or "ftp" in query or 21 in open_ports:
                    command = "ftp"
                    print(f"  ğŸ” Medusa: FTP detected")
                elif ":3389" in target or "rdp" in query or 3389 in open_ports:
                    command = "rdp"
                    print(f"  ğŸ” Medusa: RDP detected")
                elif ":3306" in target or "mysql" in query or 3306 in open_ports:
                    command = "mysql"
                    print(f"  ğŸ” Medusa: MySQL detected")
                elif url.startswith("http") or 80 in open_ports or 443 in open_ports:
                    # Default to HTTP for web targets
                    command = "http"
                    print(f"  ğŸ” Medusa: Web target, using HTTP Basic Auth brute-force")
                else:
                    # Fallback to HTTP (most web servers)
                    command = "http"
                    print(f"  ğŸ” Medusa: Defaulting to HTTP (web most common)")
        
        # Use specified command or first available
        if command is None:
            available_commands = list(spec.commands.keys())
            
            # If multiple commands, ask LLM to pick the best one
            if len(available_commands) > 1:
                user_query = state.get("query", "").lower()
                
                # Build command descriptions for LLM
                cmd_descriptions = []
                for cmd_name in available_commands:
                    cmd_template = spec.commands[cmd_name]
                    args = " ".join(cmd_template.args) if hasattr(cmd_template, 'args') else ""
                    cmd_descriptions.append(f"- {cmd_name}: {args[:80]}")
                
                # Quick keyword-to-command mapping first
                keyword_map = {
                    # Nmap
                    "os": "os_detect", "version": "version_scan", "operating system": "os_detect",
                    "aggressive": "aggressive", "stealth": "syn_scan", "syn": "syn_scan",
                    "udp": "udp_scan", "full": "full_scan", "vuln": "vuln_scan",
                    "all ports": "full_scan", "service": "version_scan",
                    # Nuclei
                    "fast": "scan_fast", "quick": "scan_fast", "all": "scan_all",
                    # Gobuster
                    "redirect": "dir_redirects", "dns": "dns",
                    # Hydra/Medusa
                    "ssh": "ssh", "ftp": "ftp", "mysql": "mysql", "rdp": "rdp",
                    # theHarvester
                    "subdomain": "subdomains", "email": "all",
                    # passgen
                    "keyword": "keywords",
                }
                
                # Check for keyword match
                for keyword, cmd in keyword_map.items():
                    if keyword in user_query and cmd in available_commands:
                        command = cmd
                        print(f"  ğŸ¯ Selected command '{cmd}' based on keyword '{keyword}'")
                        break
                
                # If still no match, use first available
                if command is None:
                    command = available_commands[0]
            else:
                command = available_commands[0]
        
        print(f"  ğŸ”§ Executing {tool_name}:{command}")
        
        # Define callback for streaming output
        import sys
        def stream_callback(line: str):
            """Print each line of output in real-time."""
            if line.strip():
                # Use ANSI colors for immediate output
                GREEN = "\033[32m"
                RED = "\033[31m"
                YELLOW = "\033[33m"
                DIM = "\033[2m"
                RESET = "\033[0m"
                
                if "open" in line.lower() or "found" in line.lower():
                    sys.stdout.write(f"    {GREEN}{line}{RESET}\n")
                elif "error" in line.lower() or "failed" in line.lower():
                    sys.stdout.write(f"    {RED}{line}{RESET}\n")
                elif "warning" in line.lower():
                    sys.stdout.write(f"    {YELLOW}{line}{RESET}\n")
                else:
                    sys.stdout.write(f"    {DIM}{line}{RESET}\n")
                sys.stdout.flush()
        
        # Use streaming execution
        result = registry.execute_stream(
            tool_name, 
            command, 
            tool_params,
            line_callback=stream_callback
        )
        
        results[tool_name] = {
            "success": result.success,
            "output": result.output,
            "error": result.error
        }
        
        # Update context
        if result.success:
            output = result.output
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # SUBDOMAIN ENUMERATION TOOLS
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if tool_name in ["subfinder", "amass", "bbot"]:
                context["has_subdomains"] = True
                context["last_domain"] = params.get("domain", "")
                # Store actual subdomains
                lines = output.strip().split("\n")
                subdomains = [l.strip() for l in lines if l.strip() and '.' in l]
                context["subdomain_count"] = len(subdomains)
                context["subdomains"] = subdomains[:50]  # Store up to 50
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # PORT SCANNING TOOLS
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            elif tool_name == "nmap":
                context["has_ports"] = True
                context["last_target"] = params.get("target", "")
                
                # Parse open ports with service info
                open_ports = []
                import re
                # Match lines like: 22/tcp   open  ssh     OpenSSH 8.2
                port_pattern = r'(\d+)/(tcp|udp)\s+open\s+(\S+)\s*(.*)?'
                for match in re.finditer(port_pattern, output):
                    port_info = {
                        "port": int(match.group(1)),
                        "protocol": match.group(2),
                        "service": match.group(3),
                        "version": match.group(4).strip() if match.group(4) else ""
                    }
                    open_ports.append(port_info)
                
                if open_ports:
                    context["open_ports"] = open_ports
                    context["port_count"] = len(open_ports)
                
                # Parse OS detection
                os_match = re.search(r'OS details?:\s*(.+)', output)
                if os_match:
                    context["os_detected"] = os_match.group(1).strip()
            
            elif tool_name == "masscan":
                context["has_ports"] = True
                context["last_target"] = params.get("target", "")
                
                # Parse masscan output: "open tcp 80 192.168.1.1"
                import re
                open_ports = []
                port_pattern = r'open\s+(tcp|udp)\s+(\d+)\s+(\S+)'
                for match in re.finditer(port_pattern, output):
                    open_ports.append({
                        "port": int(match.group(2)),
                        "protocol": match.group(1),
                        "ip": match.group(3)
                    })
                if open_ports:
                    context["open_ports"] = open_ports
                    context["port_count"] = len(open_ports)
            
            elif tool_name == "httpx":
                context["has_http_probes"] = True
                # Parse httpx output with status codes and tech
                http_probes = []
                for line in output.strip().split("\n"):
                    if line.strip() and ("http://" in line or "https://" in line):
                        http_probes.append(line.strip())
                if http_probes:
                    context["http_probes"] = http_probes[:50]
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # VULNERABILITY SCANNING TOOLS
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            elif tool_name == "nuclei":
                context["has_nuclei"] = True
                context["vuln_scan_done"] = True
                
                # Parse nuclei findings: [severity] [template-id] matched
                import re
                vulnerabilities = []
                # Match: [critical] [cve-2021-xxxx] http://target
                vuln_pattern = r'\[(critical|high|medium|low|info)\]\s*\[([^\]]+)\]\s*(.+)'
                for match in re.finditer(vuln_pattern, output, re.IGNORECASE):
                    vulnerabilities.append({
                        "severity": match.group(1).lower(),
                        "template": match.group(2),
                        "matched": match.group(3).strip()
                    })
                if vulnerabilities:
                    context["vulnerabilities"] = vulnerabilities
                    context["vuln_count"] = len(vulnerabilities)
                    # Count by severity
                    context["critical_vulns"] = len([v for v in vulnerabilities if v["severity"] == "critical"])
                    context["high_vulns"] = len([v for v in vulnerabilities if v["severity"] == "high"])
            
            elif tool_name == "nikto":
                context["has_nikto"] = True
                context["vuln_scan_done"] = True
                
                # Parse nikto findings: + OSVDB-xxxx: /path: Description
                nikto_findings = []
                for line in output.strip().split("\n"):
                    if line.strip().startswith("+") and ":" in line:
                        nikto_findings.append(line.strip()[2:])  # Remove "+ "
                if nikto_findings:
                    context["nikto_findings"] = nikto_findings[:50]
            
            elif tool_name == "sqlmap":
                context["has_sqlmap"] = True
                # Check if vulnerable
                if "is vulnerable" in output.lower() or "sqli" in output.lower():
                    context["sqli_vulnerable"] = True
                # Parse databases if found
                import re
                db_match = re.search(r'available databases \[(\d+)\]:', output)
                if db_match:
                    context["databases_found"] = int(db_match.group(1))
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # WEB DISCOVERY TOOLS
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            elif tool_name in ["gobuster", "katana"]:
                context["has_web_discovery"] = True
                
                # Parse discovered paths
                discovered_paths = []
                for line in output.strip().split("\n"):
                    line = line.strip()
                    # gobuster: /admin (Status: 200) or just paths
                    if line and ("/" in line or "http" in line):
                        # Extract just the path/URL
                        import re
                        path_match = re.search(r'(https?://[^\s]+|/[^\s\(]+)', line)
                        if path_match:
                            discovered_paths.append(path_match.group(1))
                if discovered_paths:
                    context["discovered_paths"] = list(set(discovered_paths))[:100]
                    context["path_count"] = len(context["discovered_paths"])
            
            elif tool_name == "ffuf":
                context["has_web_discovery"] = True
                # Parse ffuf output
                discovered_paths = []
                for line in output.strip().split("\n"):
                    if line.strip() and not line.startswith("["):
                        # ffuf shows: path [Status: 200, Size: 1234]
                        import re
                        path_match = re.search(r'^(\S+)', line.strip())
                        if path_match:
                            discovered_paths.append(path_match.group(1))
                if discovered_paths:
                    context["discovered_paths"] = context.get("discovered_paths", []) + discovered_paths
                    context["discovered_paths"] = list(set(context["discovered_paths"]))[:100]
            
            elif tool_name == "feroxbuster":
                context["has_web_discovery"] = True
                discovered_paths = []
                for line in output.strip().split("\n"):
                    if "http" in line:
                        import re
                        url_match = re.search(r'(https?://[^\s]+)', line)
                        if url_match:
                            discovered_paths.append(url_match.group(1))
                if discovered_paths:
                    context["discovered_paths"] = list(set(discovered_paths))[:100]
            
            elif tool_name == "dirsearch":
                context["has_web_discovery"] = True
                discovered_paths = []
                for line in output.strip().split("\n"):
                    if line.strip() and ("200" in line or "301" in line or "302" in line or "403" in line):
                        import re
                        path_match = re.search(r'(https?://[^\s]+|/[^\s]+)', line)
                        if path_match:
                            discovered_paths.append(path_match.group(1))
                if discovered_paths:
                    context["discovered_paths"] = list(set(discovered_paths))[:100]
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # WEB TECHNOLOGY DETECTION
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            elif tool_name == "wpscan":
                context["has_wpscan"] = True
                
                # Parse WordPress version
                import re
                ver_match = re.search(r'WordPress version:\s*(\S+)', output)
                if ver_match:
                    context["wordpress_version"] = ver_match.group(1)
                
                # Parse users
                users = []
                user_pattern = r'\[i\] User\(s\) Identified:.*?(?=\[\+\]|\[!\]|$)'
                user_section = re.search(user_pattern, output, re.DOTALL)
                if user_section:
                    for line in user_section.group(0).split("\n"):
                        if "| - " in line:
                            users.append(line.replace("| - ", "").strip())
                if users:
                    context["wp_users"] = users
                
                # Parse vulnerable plugins
                vuln_plugins = re.findall(r'\[!\].*vulnerable.*?:\s*(\S+)', output, re.IGNORECASE)
                if vuln_plugins:
                    context["wp_vulnerable_plugins"] = vuln_plugins
            
            elif tool_name == "whatweb":
                context["has_whatweb"] = True
                
                # Parse technologies from whatweb output
                technologies = []
                import re
                # WhatWeb shows: [tech1] [tech2] [tech3]
                tech_pattern = r'\[([^\]]+)\]'
                for match in re.finditer(tech_pattern, output):
                    tech = match.group(1)
                    if tech and len(tech) < 50:  # Avoid long descriptions
                        technologies.append(tech)
                if technologies:
                    context["web_technologies"] = list(set(technologies))[:30]
            
            elif tool_name == "wafw00f":
                context["has_waf_check"] = True
                
                # Parse WAF detection
                if "is behind" in output.lower():
                    context["waf_detected"] = True
                    import re
                    waf_match = re.search(r'is behind\s+(.+?)(?:\s+WAF|\s*$)', output, re.IGNORECASE)
                    if waf_match:
                        context["waf_name"] = waf_match.group(1).strip()
                elif "no waf" in output.lower():
                    context["waf_detected"] = False
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # BRUTE FORCE TOOLS
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            elif tool_name == "hydra":
                context["has_hydra"] = True
                
                # Parse cracked credentials: [port][service] host login: user password: pass
                cracked = []
                import re
                cred_pattern = r'\[(\d+)\]\[(\w+)\]\s+host:\s*(\S+)\s+login:\s*(\S+)\s+password:\s*(\S+)'
                for match in re.finditer(cred_pattern, output):
                    cracked.append({
                        "port": match.group(1),
                        "service": match.group(2),
                        "host": match.group(3),
                        "username": match.group(4),
                        "password": match.group(5)
                    })
                if cracked:
                    context["cracked_credentials"] = cracked
                    context["creds_count"] = len(cracked)
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # EXPLOIT TOOLS
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            elif tool_name == "searchsploit":
                context["has_searchsploit"] = True
                
                # Parse exploits: Title | Path
                exploits = []
                for line in output.strip().split("\n"):
                    if "|" in line and "/" in line:
                        parts = line.split("|")
                        if len(parts) >= 2:
                            title = parts[0].strip()
                            path = parts[1].strip()
                            if title and path and not title.startswith("-"):
                                exploits.append({
                                    "title": title,
                                    "path": path
                                })
                if exploits:
                    context["exploits_found"] = exploits
                    context["exploit_count"] = len(exploits)
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # NETWORK/SMB TOOLS
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            elif tool_name == "enum4linux":
                context["has_enum4linux"] = True
                
                # Parse SMB shares
                shares = []
                import re
                share_pattern = r'^\s*(\S+)\s+Disk\s+(.*)$'
                for match in re.finditer(share_pattern, output, re.MULTILINE):
                    shares.append(match.group(1))
                if shares:
                    context["smb_shares"] = shares
                
                # Parse users
                users = []
                user_pattern = r'user:\[([^\]]+)\]'
                for match in re.finditer(user_pattern, output):
                    users.append(match.group(1))
                if users:
                    context["smb_users"] = list(set(users))
            
            elif tool_name == "smbclient":
                context["has_smbclient"] = True
                
                # Parse shares from smbclient -L output
                shares = []
                for line in output.strip().split("\n"):
                    if "Disk" in line or "IPC" in line or "Print" in line:
                        parts = line.strip().split()
                        if parts:
                            shares.append(parts[0])
                if shares:
                    context["smb_shares"] = shares
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # OSINT TOOLS
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            elif tool_name == "theHarvester":
                # Parse theHarvester output to store emails, hosts, IPs, subdomains
                context["last_domain"] = params.get("domain", "")
                
                # Parse emails
                if "[*] Emails found:" in output:
                    email_section = output.split("[*] Emails found:")[1]
                    # Find next section marker or end
                    for marker in ["[*] Hosts found:", "[*] IPs found:", "[*] No ", "[*] Performing"]:
                        if marker in email_section:
                            email_section = email_section.split(marker)[0]
                            break
                    emails = [line.strip() for line in email_section.strip().split("\n") 
                              if line.strip() and "@" in line and not line.startswith("-")]
                    if emails:
                        context["emails"] = emails
                        context["email_count"] = len(emails)
                
                # Parse hosts/subdomains
                if "[*] Hosts found:" in output:
                    hosts_section = output.split("[*] Hosts found:")[1]
                    for marker in ["[*] Performing", "[*] No ", "Read "]:
                        if marker in hosts_section:
                            hosts_section = hosts_section.split(marker)[0]
                            break
                    hosts = [line.strip() for line in hosts_section.strip().split("\n") 
                             if line.strip() and "." in line and not line.startswith("-") and not line.startswith("[")]
                    if hosts:
                        context["hosts"] = hosts[:100]  # Store up to 100
                        context["host_count"] = len(hosts)
                        # Also extract unique subdomains (host before colon if present)
                        subdomains = list(set([h.split(":")[0] for h in hosts if "." in h.split(":")[0]]))
                        context["subdomains"] = subdomains[:50]
                        context["subdomain_count"] = len(subdomains)
                        context["has_subdomains"] = True
                
                # Parse IPs
                if "[*] IPs found:" in output:
                    ips_section = output.split("[*] IPs found:")[1]
                    for marker in ["[*] Emails found:", "[*] Hosts found:", "[*] No ", "[*] Performing"]:
                        if marker in ips_section:
                            ips_section = ips_section.split(marker)[0]
                            break
                    ips = [line.strip() for line in ips_section.strip().split("\n") 
                           if line.strip() and (line.strip()[0].isdigit() or line.strip().startswith("2"))]
                    if ips:
                        context["ips"] = ips
                        context["ip_count"] = len(ips)
                
                # Parse ASNs
                if "[*] ASNS found:" in output or "[*] ASNs found:" in output:
                    asn_marker = "[*] ASNS found:" if "[*] ASNS found:" in output else "[*] ASNs found:"
                    asn_section = output.split(asn_marker)[1]
                    for marker in ["[*] Interesting", "[*] IPs", "[*] Emails", "[*] Hosts"]:
                        if marker in asn_section:
                            asn_section = asn_section.split(marker)[0]
                            break
                    asns = [line.strip() for line in asn_section.strip().split("\n") 
                            if line.strip() and line.strip().upper().startswith("AS")]
                    if asns:
                        context["asns"] = asns
                
                # Parse interesting URLs
                if "[*] Interesting Urls found:" in output:
                    urls_section = output.split("[*] Interesting Urls found:")[1]
                    for marker in ["[*] No ", "[*] IPs", "[*] Emails", "[*] Hosts", "[*] LinkedIn"]:
                        if marker in urls_section:
                            urls_section = urls_section.split(marker)[0]
                            break
                    urls = [line.strip() for line in urls_section.strip().split("\n") 
                            if line.strip() and line.strip().startswith("http")]
                    if urls:
                        context["interesting_urls"] = urls
    
    # Track which tools have been run (prevent loops)
    tools_run = context.get("tools_run", [])
    tools_run.extend(tools)
    context["tools_run"] = list(set(tools_run))  # Deduplicate
    
    return {
        **state,
        "execution_results": results,
        "context": context,
        "next_action": "analyze"
    }


def analyzer_node(state: AgentState) -> AgentState:
    """
    LLM analyzes execution results.
    
    NEW: Enriches results with CVE data from RAG.
    
    Decides:
    - DONE: Goal achieved, format and return results
    - CONTINUE: Suggest next step
    - ASK_USER: Need clarification
    """
    llm = OllamaClient()
    results = state.get("execution_results", {})
    context = state.get("context", {})
    
    # === CHECK IF ANY TOOLS SUCCEEDED ===
    successful_tools = [t for t, d in results.items() if d.get("success")]
    failed_tools = [t for t, d in results.items() if not d.get("success")]
    
    if not successful_tools:
        # ALL tools failed - don't send to LLM, show clear error
        error_msg = "âš ï¸ **All scans failed or timed out:**\n\n"
        for tool, data in results.items():
            error_msg += f"- **{tool}**: {data.get('error', 'Timeout/Unknown error')}\n"
        error_msg += "\n**Suggestions:**\n"
        error_msg += "- Check if target is accessible\n"
        error_msg += "- Try a different tool or target\n"
        error_msg += "- Check tool installation with `/tools`"
        
        return {
            **state,
            "response": error_msg,
            "next_action": "respond"
        }
    
    # Format results for LLM - use more context for better analysis
    results_str = ""
    for tool, data in results.items():
        if data.get("success"):
            output = data.get("output", "")[:4000]
            results_str += f"\n{tool}: SUCCESS\n{output}\n"
        else:
            results_str += f"\n{tool}: FAILED - {data.get('error', 'Unknown error')}\n"
    
    # ============================================================
    cve_context = ""
    try:
        from app.rag.cve_rag import search_cves
        
        # ONLY look for actual technology keywords in results
        # Don't search for domain names - they won't match CVEs
        tech_keywords = [
            "wordpress", "apache", "nginx", "php", "mysql", "ssh", "openssh",
            "ftp", "rdp", "smb", "tomcat", "jenkins", "redis", "mongodb",
            "postgresql", "mariadb", "iis", "exchange", "sharepoint",
            "drupal", "joomla", "magento", "cpanel", "plesk", "webmin",
            "proftpd", "vsftpd", "openssl", "cloudflare", "ubuntu", "debian",
            "centos", "windows", "fortios", "fortigate", "cisco", "mikrotik"
        ]
        
        detected_tech = []
        results_lower = results_str.lower()
        for tech in tech_keywords:
            if tech in results_lower:
                detected_tech.append(tech)
        
        # Also look for version patterns like "Apache/2.4.41"
        import re
        version_pattern = r'([a-zA-Z]+)[/\s](\d+\.\d+(?:\.\d+)?)'
        versions = re.findall(version_pattern, results_str)
        for name, ver in versions:
            if name.lower() not in ["http", "www", "ssl", "tls"]:
                detected_tech.append(f"{name} {ver}")
        
        # Store detected tech for exploit tools to use
        if detected_tech:
            context["detected_tech"] = list(set(detected_tech))[:10]
            search_query = " ".join(detected_tech[:3])
            cve_results = search_cves(search_query, n_results=5, severity="high")
            
            if cve_results.get("cves"):
                # Store CVEs in context for later display (/cve command)
                context["last_cves"] = cve_results["cves"]
                context["cve_query"] = search_query
                
                cve_context = "\n\nRELEVANT CVEs:\n"
                for cve in cve_results["cves"][:3]:
                    cve_id = cve.get("cve_id", "Unknown")
                    desc = cve.get("description", "")[:100]
                    severity = cve.get("severity", "Unknown")
                    cve_context += f"- {cve_id} ({severity}): {desc}...\n"
                print(f"  ğŸ” CVE RAG: {len(cve_results['cves'])} CVEs for detected tech: {detected_tech[:3]}")
        else:
            print(f"  â„¹ï¸ CVE RAG: No technologies detected in results (need port/service scan first)")
    except Exception as e:
        print(f"  âš ï¸ CVE RAG: {e}")
    
    # ============================================================
    # PURE LLM ANALYSIS - Attack Chain Focus
    # ============================================================
    
    prompt = f'''You are an offensive security expert analyzing scan results. Your goal is to find the FASTEST PATH TO EXPLOITATION.

SCAN RESULTS:
{results_str}
{cve_context}

CONTEXT:
- Target domain: {context.get('last_domain', 'unknown')}
- Subdomains found: {context.get('subdomain_count', 0)}
- Ports scanned: {context.get('has_ports', False)}
- Technologies detected: {context.get('detected_tech', [])}
- Tools already run: {context.get('tools_run', [])}

YOUR ANALYSIS MUST:

1. **IDENTIFY ATTACK VECTORS** - What can be exploited on the ACTUAL TARGET?
   - Exposed admin panels (cPanel, WHM, phpMyAdmin) â†’ Default creds / Brute force
   - Open SSH/FTP/RDP â†’ Brute force with hydra
   - Web forms/login pages â†’ SQL injection with sqlmap
   - Known CVEs in detected versions â†’ Search exploits with searchsploit
   - File upload endpoints â†’ Web shell upload
   - API endpoints â†’ Parameter fuzzing with ffuf

2. **PRIORITIZE BY EXPLOITABILITY** (most likely to succeed first)
   - Critical: Known CVEs with public exploits
   - High: Default credentials, unauthenticated access
   - Medium: Requires brute force or fuzzing
   - Low: Information disclosure only

3. **RECOMMEND NEXT ATTACK STEP** - What tool gets us closer to shell?
   - Found login page? â†’ Use hydra for brute force
   - Found web form with parameters? â†’ Use sqlmap for SQL injection
   - Found old software version? â†’ Use searchsploit for exploits
   - Found open ports? â†’ Use nmap scripts for vuln scan
   - Need to find endpoints? â†’ Use gobuster or katana first

CRITICAL DISTINCTION - UNDERSTAND TOOL OUTPUT TYPES:
- **searchsploit** results are from Exploit-DB database. The paths in exploit titles (like /music/ajax.php) 
  are examples from the VULNERABLE SOFTWARE, NOT paths that exist on the target domain!
- If searchsploit found MySQL exploits, it means MySQL software has known vulnerabilities.
  You must FIRST discover actual endpoints using gobuster/katana, THEN apply exploitation.
- **nuclei/nmap** results ARE from the actual target and can be exploited directly.
- **subdomain/port scans** show what's actually accessible on the target.

RESPOND IN JSON FORMAT:
{{
    "findings": [
        {{"issue": "Specific vulnerability", "attack": "How to exploit it", "severity": "Critical/High/Medium/Low"}}
    ],
    "best_attack_vector": "The most promising attack path",
    "summary": "Brief summary of attack surface",
    "next_tool": "tool_name",
    "next_target": "specific URL or host FROM THE ACTUAL TARGET (use {context.get('last_domain', 'target.com')})",
    "next_reason": "Why this tool will get us closer to exploitation"
}}

IMPORTANT:
- Focus on ACTIONABLE findings that lead to exploitation
- Suggest ONE specific next tool (not a list)
- Use ACTUAL target URLs/hosts, not example paths from exploit database entries
- If searchsploit was just run, suggest gobuster/katana to find real endpoints before sqlmap
- Prioritize quick wins: default creds, known CVEs, misconfigurations
'''
    
    response = llm.generate(prompt, timeout=60)
    
    try:
        # Robust JSON extraction with multiple repair strategies
        clean_response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL)
        
        # Try to extract JSON
        json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', clean_response, re.DOTALL)
        
        data = None
        if json_match:
            json_str = json_match.group()
            
            # Strategy 1: Direct parse
            try:
                data = json.loads(json_str)
            except json.JSONDecodeError:
                pass
            
            # Strategy 2: Fix single quotes to double quotes
            if data is None:
                try:
                    # Replace single quotes with double (carefully)
                    fixed = re.sub(r"'([^']*)':", r'"\1":', json_str)
                    fixed = re.sub(r": '([^']*)'", r': "\1"', fixed)
                    data = json.loads(fixed)
                except json.JSONDecodeError:
                    pass
            
            # Strategy 3: Fix unescaped characters
            if data is None:
                try:
                    # Remove control characters
                    fixed = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_str)
                    # Fix trailing commas
                    fixed = re.sub(r',\s*}', '}', fixed)
                    fixed = re.sub(r',\s*]', ']', fixed)
                    data = json.loads(fixed)
                except json.JSONDecodeError:
                    pass
            
            # Strategy 4: Extract just the key fields manually
            if data is None:
                data = {}
                # Try to extract next_tool
                tool_match = re.search(r'"next_tool"\s*:\s*"([^"]+)"', clean_response)
                if tool_match:
                    data["next_tool"] = tool_match.group(1)
                # Try to extract best_attack
                attack_match = re.search(r'"best_attack"\s*:\s*"([^"]+)"', clean_response)
                if attack_match:
                    data["best_attack"] = attack_match.group(1)
                # Try to extract summary
                summary_match = re.search(r'"summary"\s*:\s*"([^"]+)"', clean_response)
                if summary_match:
                    data["summary"] = summary_match.group(1)
        
        if data:
            
            findings = data.get("findings", [])
            findings_str = ""
            if findings:
                findings_str = "\n\n## ğŸ¯ Attack Vectors Identified\n\n"
                for f in findings:
                    severity = f.get("severity", "Unknown")
                    badge = {"Critical": "ğŸ”´", "High": "ğŸŸ ", "Medium": "ğŸŸ¡", "Low": "ğŸŸ¢"}.get(severity, "âšª")
                    findings_str += f"{badge} **{f.get('issue')}** ({severity})\n"
                    # Show attack method if present
                    attack = f.get("attack") or f.get("risk", "")
                    if attack:
                        findings_str += f"   â†’ Exploit: {attack}\n\n"
            
            # Best attack vector
            best_attack = data.get("best_attack_vector", "")
            
            # Next step recommendation
            next_tool = data.get("next_tool") or (data.get("next_tools", [None])[0] if data.get("next_tools") else None)
            next_target = data.get("next_target", "")
            next_reason = data.get("next_reason", "")
            summary = data.get("summary", "")
            
            # Build response with attack-focused analysis
            response_text = ""
            
            # Show attack vectors first
            if findings_str:
                response_text += findings_str
            
            # Show best attack vector
            if best_attack:
                response_text += f"\n## âš¡ Best Attack Vector\n{best_attack}\n"
            
            # Show analysis summary
            if summary:
                response_text += f"\n## ğŸ“Š Analysis\n{summary}\n"
            
            # NOTE: Removed "Scan Details" section since live streaming 
            # now shows all tool output in real-time. No need to duplicate.
            
            # Show next step with specific target
            if next_tool:
                next_step = f"Use **{next_tool}**"
                if next_target:
                    next_step += f" on `{next_target}`"
                if next_reason:
                    next_step += f" - {next_reason}"
                response_text += f"\n\n**ğŸ’¡ Next Attack Step:** {next_step}"
            elif next_reason:
                response_text += f"\n\n**ğŸ’¡ Recommended next step:** {next_reason}"
            
            return {
                **state,
                "response": response_text,
                "context": context,
                "next_action": "respond"
            }
        else:
            print(f"  âš ï¸ No JSON in analyzer response, showing raw results")
    except Exception as e:
        print(f"  âš ï¸ Analyzer parse error: {e}")
    
    # Fallback - show formatted results (LLM failed to parse)
    formatted = ""
    raw_results = _format_results(results)
    if not raw_results or raw_results == "No results":
        formatted = f"**Scan completed**\n\n"
        for tool, data in results.items():
            if data.get("success"):
                output = data.get("output", "")[:2000]
                formatted += f"### {tool}\n```\n{output}\n```\n\n"
            else:
                formatted += f"### {tool}\nâŒ {data.get('error', 'Unknown error')}\n\n"
    else:
        formatted = raw_results
    
    # Clear message that LLM analysis failed - no hardcoded guidance
    llm_failure_notice = "\n\nâš ï¸ **LLM analysis failed to parse.** Raw tool output shown above. Please interpret the results and decide next steps yourself."
    
    return {
        **state,
        "response": formatted + llm_failure_notice,
        "next_action": "respond"
    }


def respond_node(state: AgentState) -> AgentState:
    """Format and return final response."""
    # If we have a suggestion waiting for confirmation
    if state.get("suggestion_message") and state.get("suggested_tools"):
        return {
            **state,
            "response": state["suggestion_message"],
            "next_action": "end"
        }
    
    # If there's already a response, use it
    if state.get("response"):
        return {**state, "next_action": "end"}
    
    # Fallback if no response
    return {
        **state,
        "response": "I couldn't process that request. Please try again with more details.",
        "next_action": "end"
    }


def question_node(state: AgentState) -> AgentState:
    """Answer simple questions using context and conversation history."""
    llm = OllamaClient()
    
    # Build context from stored data
    context = state.get("context", {})
    messages = state.get("messages", [])
    
    # Get last scan results from messages
    last_results = ""
    for msg in reversed(messages[-10:]):
        if msg.get("role") == "assistant" and "port" in msg.get("content", "").lower():
            last_results = msg.get("content", "")[:500]
            break
    
    # Build context string
    context_str = f"""
Domain: {context.get('last_domain', 'Not set')}
Subdomains found: {context.get('subdomain_count', 0)}
Last scan: {context.get('last_scan', 'None')}

Recent output:
{last_results if last_results else 'No recent scan results'}
"""
    
    prompt = f"""You are SNODE, a penetration testing AI assistant.
Answer this question using the context below:

CONTEXT:
{context_str}

QUESTION: {state["query"]}

If the question is about previous results, use the context to answer.
If you don't have the information, say so briefly.
"""
    
    response = llm.generate(prompt, timeout=30)
    
    return {
        **state,
        "response": response or "I don't have that information. Try running a scan first.",
        "next_action": "end"
    }


def memory_query_node(state: AgentState) -> AgentState:
    """
    Retrieve and display stored data from memory/context.
    
    Handles requests like:
    - "show me the subdomains"
    - "list the findings"
    - "what did we find"
    - "show me emails"
    """
    context = state.get("context", {})
    query = state.get("query", "").lower()
    
    response_parts = []
    
    # Get domain
    domain = context.get("last_domain", "Unknown target")
    response_parts.append(f"## ğŸ“Š Stored Data for {domain}\n")
    
    # Emails
    emails = context.get("emails", [])
    if emails:
        response_parts.append(f"### ğŸ“§ Emails ({len(emails)} found)\n")
        for email in emails:
            response_parts.append(f"  â€¢ {email}")
        response_parts.append("")
    
    # Subdomains
    subdomains = context.get("subdomains", [])
    subdomain_count = context.get("subdomain_count", len(subdomains))
    
    if subdomains:
        response_parts.append(f"### ğŸŒ Subdomains ({subdomain_count} found)\n")
        for sub in subdomains:
            response_parts.append(f"  â€¢ {sub}")
        response_parts.append("")
    elif subdomain_count > 0:
        response_parts.append(f"### ğŸŒ Subdomains\n  {subdomain_count} subdomains discovered (list not in memory)\n")
    
    # Hosts
    hosts = context.get("hosts", [])
    if hosts:
        response_parts.append(f"### ğŸ–¥ï¸ Hosts ({len(hosts)} found)\n")
        for host in hosts:
            response_parts.append(f"  â€¢ {host}")
        response_parts.append("")
    
    # IPs
    ips = context.get("ips", [])
    if ips:
        response_parts.append(f"### ğŸ”¢ IP Addresses ({len(ips)} found)\n")
        for ip in ips:
            response_parts.append(f"  â€¢ {ip}")
        response_parts.append("")
    
    # ASNs
    asns = context.get("asns", [])
    if asns:
        response_parts.append(f"### ğŸ¢ ASNs ({len(asns)} found)\n")
        for asn in asns:
            response_parts.append(f"  â€¢ {asn}")
        response_parts.append("")
    
    # Interesting URLs
    interesting_urls = context.get("interesting_urls", [])
    if interesting_urls:
        response_parts.append(f"### ğŸ”— Interesting URLs ({len(interesting_urls)} found)\n")
        for url in interesting_urls:
            response_parts.append(f"  â€¢ {url}")
        response_parts.append("")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PORT SCAN RESULTS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    open_ports = context.get("open_ports", [])
    if open_ports:
        response_parts.append(f"### ğŸ”Œ Open Ports ({len(open_ports)} found)\n")
        for port in open_ports:
            if isinstance(port, dict):
                port_str = f"{port.get('port')}/{port.get('protocol', 'tcp')}"
                service = port.get('service', '')
                version = port.get('version', '')
                if service:
                    port_str += f"  {service}"
                if version:
                    port_str += f" ({version})"
                response_parts.append(f"  â€¢ {port_str}")
            else:
                response_parts.append(f"  â€¢ {port}")
        response_parts.append("")
    
    # OS Detection
    if context.get("os_detected"):
        response_parts.append(f"### ğŸ’» OS Detected\n  {context['os_detected']}\n")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # VULNERABILITY RESULTS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    vulnerabilities = context.get("vulnerabilities", [])
    if vulnerabilities:
        critical = context.get("critical_vulns", 0)
        high = context.get("high_vulns", 0)
        response_parts.append(f"### ğŸ”“ Vulnerabilities ({len(vulnerabilities)} found)")
        if critical or high:
            response_parts.append(f"  ğŸ”´ Critical: {critical} | ğŸŸ  High: {high}\n")
        else:
            response_parts.append("")
        for vuln in vulnerabilities:
            severity = vuln.get("severity", "unknown")
            template = vuln.get("template", "unknown")
            matched = vuln.get("matched", "")
            badge = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢", "info": "â„¹ï¸"}.get(severity, "âšª")
            response_parts.append(f"  {badge} [{template}] {matched}")
        response_parts.append("")
    
    # Nikto Findings
    nikto_findings = context.get("nikto_findings", [])
    if nikto_findings:
        response_parts.append(f"### ğŸ•·ï¸ Nikto Findings ({len(nikto_findings)} found)\n")
        for finding in nikto_findings:
            response_parts.append(f"  â€¢ {finding}")
        response_parts.append("")
    
    # SQLi Results
    if context.get("sqli_vulnerable"):
        dbs = context.get("databases_found", 0)
        response_parts.append(f"### ï¿½ SQL Injection\n  âš ï¸ Target is VULNERABLE to SQL injection!")
        if dbs:
            response_parts.append(f"  ğŸ“ {dbs} databases discovered")
        response_parts.append("")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # WEB DISCOVERY RESULTS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    discovered_paths = context.get("discovered_paths", [])
    if discovered_paths:
        response_parts.append(f"### ğŸ“‚ Discovered Paths ({len(discovered_paths)} found)\n")
        for path in discovered_paths:
            response_parts.append(f"  â€¢ {path}")
        response_parts.append("")
    
    # HTTP Probes
    http_probes = context.get("http_probes", [])
    if http_probes:
        response_parts.append(f"### ğŸŒ HTTP Probes ({len(http_probes)} found)\n")
        for probe in http_probes:
            response_parts.append(f"  â€¢ {probe}")
        response_parts.append("")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # WORDPRESS INFO
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if context.get("wordpress_version"):
        response_parts.append(f"### ğŸ“¦ WordPress Info")
        response_parts.append(f"  Version: {context['wordpress_version']}")
        if context.get("wp_users"):
            response_parts.append(f"  Users: {', '.join(context['wp_users'][:10])}")
        if context.get("wp_vulnerable_plugins"):
            response_parts.append(f"  âš ï¸ Vulnerable Plugins: {', '.join(context['wp_vulnerable_plugins'])}")
        response_parts.append("")
    
    # WAF Detection
    if context.get("has_waf_check"):
        if context.get("waf_detected"):
            waf_name = context.get("waf_name", "Unknown")
            response_parts.append(f"### ï¿½ï¸ WAF Detected\n  âš ï¸ {waf_name}\n")
        else:
            response_parts.append("### ğŸ›¡ï¸ WAF Detection\n  âœ… No WAF detected\n")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CREDENTIALS & EXPLOITS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    cracked_creds = context.get("cracked_credentials", [])
    if cracked_creds:
        response_parts.append(f"### ğŸ”‘ Cracked Credentials ({len(cracked_creds)} found)\n")
        for cred in cracked_creds:
            user = cred.get("username", "?")
            passwd = cred.get("password", "?")
            service = cred.get("service", "")
            host = cred.get("host", "")
            response_parts.append(f"  â€¢ {user}:{passwd} ({service}@{host})")
        response_parts.append("")
    
    exploits_found = context.get("exploits_found", [])
    if exploits_found:
        response_parts.append(f"### ğŸ’£ Exploits Found ({len(exploits_found)})\n")
        for exp in exploits_found:
            title = exp.get("title", "Unknown")
            response_parts.append(f"  â€¢ {title}")
        response_parts.append("")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SMB/NETWORK INFO
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    smb_shares = context.get("smb_shares", [])
    if smb_shares:
        response_parts.append(f"### ğŸ“ SMB Shares ({len(smb_shares)} found)\n")
        for share in smb_shares:
            response_parts.append(f"  â€¢ {share}")
        response_parts.append("")
    
    smb_users = context.get("smb_users", [])
    if smb_users:
        response_parts.append(f"### ğŸ‘¤ SMB Users ({len(smb_users)} found)\n")
        for user in smb_users:
            response_parts.append(f"  â€¢ {user}")
        response_parts.append("")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # TECHNOLOGY & TOOLS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Web Technologies (from whatweb)
    web_tech = context.get("web_technologies", [])
    if web_tech:
        response_parts.append(f"### ğŸ”§ Web Technologies ({len(web_tech)} found)\n")
        for tech in web_tech[:20]:
            response_parts.append(f"  â€¢ {tech}")
        response_parts.append("")
    
    # Detected Technologies (from analyzer)
    detected_tech = context.get("detected_tech", [])
    if detected_tech and not web_tech:
        response_parts.append("### ğŸ”§ Detected Technologies\n")
        for tech in detected_tech[:20]:
            response_parts.append(f"  â€¢ {tech}")
        response_parts.append("")
    
    # Tools run
    tools_run = context.get("tools_run", [])
    if tools_run:
        response_parts.append("### ğŸ› ï¸ Tools Executed\n")
        for tool in tools_run:
            response_parts.append(f"  â€¢ {tool}")
        response_parts.append("")
    
    # If nothing found
    if len(response_parts) <= 1:
        response_parts.append("No data stored yet. Run some scans first!")
    
    response = "\n".join(response_parts)
    
    return {
        **state,
        "response": response,
        "next_action": "end"
    }


def _format_results(results: Dict[str, Any]) -> str:
    """Format tool results for display."""
    from app.cli.display import format_tool_result
    
    parts = []
    for tool, data in results.items():
        if data.get("success"):
            formatted = format_tool_result(tool, data.get("output", ""), True)
            parts.append(formatted)
        else:
            parts.append(f"**{tool}**: Error - {data.get('error', 'Unknown')}")
    
    return "\n\n".join(parts) if parts else "No results"


# ============================================================
# GRAPH ROUTING
# ============================================================

def route_after_intent(state: AgentState) -> str:
    """Route based on intent classification."""
    intent = state.get("intent", "question")
    
    if intent == "security_task":
        return "planner"
    elif intent == "confirm":
        return "confirm"
    elif intent == "memory_query":
        return "memory_query"
    elif intent == "question":
        return "question"
    else:
        return "question"


def route_after_action(state: AgentState) -> str:
    """Route based on next_action field."""
    action = state.get("next_action", "end")
    
    # Map actions to node names
    routes = {
        "plan": "planner",
        "planner": "planner",
        "confirm": "respond",
        "executor": "executor",
        "execute": "executor",
        "analyzer": "analyzer",
        "analyze": "analyzer",
        "respond": "respond"
    }
    
    return routes.get(action, END)


# ============================================================
# BUILD GRAPH
# ============================================================

def build_graph():
    """Build the LangGraph state machine."""
    
    # Create graph
    graph = StateGraph(AgentState)
    
    # Add nodes
    graph.add_node("intent", intent_node)
    graph.add_node("planner", planner_node)
    graph.add_node("confirm", confirm_node)
    graph.add_node("executor", executor_node)
    graph.add_node("analyzer", analyzer_node)
    graph.add_node("respond", respond_node)
    graph.add_node("question", question_node)
    graph.add_node("memory_query", memory_query_node)
    
    # Set entry point
    graph.set_entry_point("intent")
    
    # Add conditional edges
    graph.add_conditional_edges(
        "intent",
        route_after_intent,
        {
            "planner": "planner",
            "confirm": "confirm",
            "memory_query": "memory_query",
            "question": "question"
        }
    )
    
    graph.add_conditional_edges(
        "planner",
        route_after_action,
        {
            "confirm": "respond",
            "respond": "respond",
            END: END
        }
    )
    
    graph.add_conditional_edges(
        "confirm",
        route_after_action,
        {
            "executor": "executor",
            "respond": "respond",
            END: END
        }
    )
    
    graph.add_conditional_edges(
        "executor",
        route_after_action,
        {
            "analyze": "analyzer",
            "analyzer": "analyzer",
            "respond": "respond",
            END: END
        }
    )
    
    graph.add_conditional_edges(
        "analyzer",
        route_after_action,
        {
            "confirm": "respond",
            "respond": "respond",
            "planner": "planner",
            END: END
        }
    )
    
    graph.add_edge("respond", END)
    graph.add_edge("question", END)
    graph.add_edge("memory_query", END)
    
    # Compile with memory
    memory = MemorySaver()
    return graph.compile(checkpointer=memory)


# ============================================================
# AGENT CLASS
# ============================================================

class LangGraphAgent:
    """
    LangGraph-powered SNODE agent.
    
    Proper flow:
    1. LLM classifies intent
    2. LLM suggests tools
    3. User confirms
    4. Code executes
    5. LLM analyzes
    
    Key feature: Uses LangChain ConversationSummaryBufferMemory for smart context.
    """
    
    def __init__(self):
        self.graph = build_graph()
        self.context = {}
        self.thread_id = "snode-session"
        self.pending_confirmation = False
        self.last_suggestion = None
        self.last_results = {}  # Store for report generation
        
        # Initialize AttackMemory with LangChain conversation memory
        try:
            from app.agent.memory import AttackMemory
            self.memory = AttackMemory(persist=True, model=get_current_model())
        except Exception as e:
            print(f"âš ï¸ Memory init failed: {e}")
            self.memory = None
        
        # Backward compatibility - keep messages list
        self.messages = []
    
    def run(self, query: str, context: Dict[str, Any] = None) -> tuple[str, Dict[str, Any], bool]:
        """
        Process user input.
        
        Returns:
            (response, context, needs_confirmation)
        """
        if context:
            self.context.update(context)
        
        # Add user message to history (both old and new memory)
        self.messages.append({"role": "user", "content": query})
        
        # If we have a pending confirmation and user says yes/no
        suggested_tools = []
        tool_params = {}
        if self.pending_confirmation and self.last_suggestion:
            suggested_tools = self.last_suggestion.get("tools", [])
            tool_params = self.last_suggestion.get("params", {})
        
        # Initial state
        state = AgentState(
            query=query,
            messages=self.messages.copy(),
            intent="",
            suggested_tools=suggested_tools,  # Pass from last suggestion
            suggestion_message="",
            tool_params=tool_params,  # Pass from last suggestion
            confirmed=False,
            selected_tools=[],
            execution_results={},
            context=self.context,
            response="",
            next_action=""
        )
        
        # Config with thread
        config = {"configurable": {"thread_id": self.thread_id}}
        
        # Run graph
        result = self.graph.invoke(state, config)
        
        # Update context
        self.context = result.get("context", self.context)
        
        # Store execution results for report generation
        if result.get("execution_results"):
            self.last_results.update(result.get("execution_results", {}))
        
        # Get response
        response = result.get("response", "No response")
        
        # Add assistant message to history (old system)
        self.messages.append({"role": "assistant", "content": response})
        
        # Save to LangChain memory (new system)
        if self.memory:
            self.memory.save_conversation_turn(query, response)
        
        # Keep last 20 messages to avoid memory bloat
        if len(self.messages) > 20:
            self.messages = self.messages[-20:]
        
        # Check if awaiting confirmation
        needs_confirmation = (
            len(result.get("suggested_tools", [])) > 0 and
            result.get("next_action") == "end" and
            not result.get("execution_results")
        )
        
        if needs_confirmation:
            self.pending_confirmation = True
            self.last_suggestion = {
                "tools": result.get("suggested_tools"),
                "params": result.get("tool_params")
            }
        else:
            self.pending_confirmation = False
            self.last_suggestion = None
        
        return response, self.context, needs_confirmation
    
    def clear_history(self):
        """Clear conversation history."""
        self.messages = []
        self.context = {}


# Factory function
def create_langgraph_agent() -> LangGraphAgent:
    return LangGraphAgent()
